DATA_ROOT: '../datasets/'
LOGS_ROOT: '../logs/'


MODEL:
  # architecture
  backbone: 'swin_base_patch4_window7_224'
  pooling: 'gem'
  embed_feat: 0
  dropout: 0.

  dsbn: False

  sync_bn: True
  samples_per_bn: 32

  mean_net: False

  # pretraining
  imagenet_pretrained: True
  source_pretrained: null


DATA:

  height: 224
  width: 224
  norm_mean: [0.485, 0.456, 0.406]
  norm_std: [0.229, 0.224, 0.225]

  TRAIN:
    # augmentation
    is_autoaug: True

    is_flip: True
    flip_prob: 0.5

    is_pad: True
    pad_size: 10

    is_blur: False
    blur_prob: 0.5

    is_erase: False
    erase_prob: 0.5

    # dual augmentation for MMT
    is_mutual_transform: False
    mutual_times: 2


TRAIN:
  seed: 2022
  deterministic: True
  # mixed precision training for PyTorch>=1.6
  amp: True

  # datasets
  datasets: {'market1501': ['trainval']}
  unsup_dataset_indexes: null

  epochs: 22
  iters: 625

  LOSS:
    losses: {'cosface': 1., 'moco': 1.}
    margin: 0.25
    gamma: 32
    queue_size: 8192
    feature_dim: 1024

  # validate
  val_dataset: 'market1501'
  val_freq: 1

  # sampler
  SAMPLER:
    num_instances: 2
    is_shuffle: True

  # data loader
  LOADER:
    samples_per_gpu: 32
    workers_per_gpu: 8

  # optim
  OPTIM:
    optim: 'adam'
    lr: 0.00004
    weight_decay: 0.0005

  SCHEDULER:
    lr_scheduler: 'cosine'
    max_epoch: 22
    warmup_factor: 0.01
    warmup_steps: 10

TEST:

  # datasets
  datasets: ['market1501',]

  # data loader
  LOADER:
    samples_per_gpu: 64
    workers_per_gpu: 8

  # ranking setting
  dist_metric: 'euclidean'
  norm_feat: True
  dist_cuda: True

  # post processing
  rerank: False
  search_type: 0 # 0,1,2 for GPU, 3 for CPU (work for faiss)
  k1: 20
  k2: 6
  lambda_value: 0.3
